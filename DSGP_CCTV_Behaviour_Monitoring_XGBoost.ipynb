{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tariqramzeengit/ML-COURSEWORK-2025/blob/main/DSGP_CCTV_Behaviour_Monitoring_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loa-vx6Nxe49"
      },
      "source": [
        "# DSGP â€” CCTV Passenger Behaviour Monitoring (Feature Engineering + XGBoost)\n",
        "\n",
        "This Colab notebook implements:\n",
        "\n",
        "- **Data preprocessing**\n",
        "- **EDA**\n",
        "- **CNN feature extraction** (EfficientNet embeddings)\n",
        "- **Feature engineering** (brightness/contrast/blur)\n",
        "- **XGBoost** classifier\n",
        "- **Evaluation**\n",
        "- **Basic prediction program**\n",
        "- *(Optional)* Video inference (frame sampling)\n",
        "\n",
        "## Dataset structure (recommended)\n",
        "\n",
        "```\n",
        "dataset/\n",
        "  train/\n",
        "    normal/\n",
        "    stealing/\n",
        "    fight/\n",
        "    medical_emergency/\n",
        "  val/\n",
        "    normal/\n",
        "    ...\n",
        "  test/\n",
        "    normal/\n",
        "    ...\n",
        "```\n",
        "\n",
        "If you only have `dataset/<class>/*` without `train/val/test`, the notebook will automatically split.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uptVJ0fDxe4-"
      },
      "source": [
        "## 1) Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNk61u8bxe4_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip -q install xgboost opencv-python scikit-learn matplotlib pandas tqdm joblib tensorflow\n",
        "\n",
        "import os, glob, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "\n",
        "import xgboost as xgb\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWJq1QV0xe4_"
      },
      "source": [
        "## 2) Mount Google Drive (recommended)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "xVI6p_Fmxe5A",
        "outputId": "bd2cc3ae-d66e-4a7f-852a-1435257a4989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-907070862.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn43fttVxe5A"
      },
      "source": [
        "Set your dataset path here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnrP7Dodxe5A"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/dataset\"  # CHANGE THIS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FDy7VZ4xe5A"
      },
      "source": [
        "## 3) Helper functions (load images + engineered features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLA1Nzprxe5A"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "IMG_SIZE = 224  # works with EfficientNetB0\n",
        "\n",
        "def list_images_and_labels(base_dir):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    classes = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n",
        "    for cls in classes:\n",
        "        paths = glob.glob(os.path.join(base_dir, cls, \"*\"))\n",
        "        paths = [p for p in paths if p.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"))]\n",
        "        image_paths.extend(paths)\n",
        "        labels.extend([cls]*len(paths))\n",
        "    return image_paths, labels\n",
        "\n",
        "def read_image(path, img_size=224):\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        return None\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    return img\n",
        "\n",
        "def simple_extra_features(img_rgb):\n",
        "    \"\"\"Lightweight feature engineering:\n",
        "    - brightness (mean gray)\n",
        "    - contrast (std gray)\n",
        "    - blur (variance of Laplacian)\n",
        "    \"\"\"\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    brightness = float(np.mean(gray))\n",
        "    contrast = float(np.std(gray))\n",
        "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
        "    blur = float(lap.var())  # lower = blurrier\n",
        "    return np.array([brightness, contrast, blur], dtype=np.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdUIl1oIxe5B"
      },
      "source": [
        "## 4) Load dataset (supports both split and unsplit datasets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AZ37_h3xe5B"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "train_dir = os.path.join(DATASET_PATH, \"train\")\n",
        "val_dir   = os.path.join(DATASET_PATH, \"val\")\n",
        "test_dir  = os.path.join(DATASET_PATH, \"test\")\n",
        "\n",
        "has_train = os.path.exists(train_dir)\n",
        "has_val   = os.path.exists(val_dir)\n",
        "has_test  = os.path.exists(test_dir)\n",
        "\n",
        "if has_train:\n",
        "    train_paths, train_labels = list_images_and_labels(train_dir)\n",
        "    if has_val:\n",
        "        val_paths, val_labels = list_images_and_labels(val_dir)\n",
        "    else:\n",
        "        val_paths, val_labels = [], []\n",
        "    if has_test:\n",
        "        test_paths, test_labels = list_images_and_labels(test_dir)\n",
        "    else:\n",
        "        test_paths, test_labels = [], []\n",
        "else:\n",
        "    all_paths, all_labels = list_images_and_labels(DATASET_PATH)\n",
        "    train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "        all_paths, all_labels, test_size=0.3, random_state=42, stratify=all_labels\n",
        "    )\n",
        "    val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "        temp_paths, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
        "    )\n",
        "\n",
        "print(\"Train:\", len(train_paths), \"Val:\", len(val_paths), \"Test:\", len(test_paths))\n",
        "print(\"Classes:\", sorted(set(train_labels)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcwEtUP3xe5B"
      },
      "source": [
        "## 5) EDA (class counts + sample grid)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wp6Hk2Sxe5B"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def plot_class_distribution(labels, title):\n",
        "    if len(labels) == 0:\n",
        "        print(title, \": (empty)\")\n",
        "        return\n",
        "    s = pd.Series(labels).value_counts().sort_index()\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.bar(s.index, s.values)\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.show()\n",
        "\n",
        "plot_class_distribution(train_labels, \"Train class distribution\")\n",
        "plot_class_distribution(val_labels, \"Val class distribution\")\n",
        "plot_class_distribution(test_labels, \"Test class distribution\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8_qQNZrxe5B"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def show_samples(paths, labels, n=12):\n",
        "    if len(paths) == 0:\n",
        "        print(\"No images to display.\")\n",
        "        return\n",
        "    idxs = random.sample(range(len(paths)), min(n, len(paths)))\n",
        "    cols = 4\n",
        "    rows = int(np.ceil(len(idxs)/cols))\n",
        "    plt.figure(figsize=(12, 3*rows))\n",
        "    for i, idx in enumerate(idxs):\n",
        "        img = read_image(paths[idx], IMG_SIZE)\n",
        "        if img is None:\n",
        "            continue\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(labels[idx])\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "show_samples(train_paths, train_labels, n=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDHnjjWbxe5C"
      },
      "source": [
        "## 6) CNN Feature Extraction (EfficientNet embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL9Ig8D0xe5C"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "base_model = EfficientNetB0(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    pooling=\"avg\",\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "def extract_embeddings(paths, labels, batch_size=32):\n",
        "    X_embed = []\n",
        "    X_extra = []\n",
        "    y_out = []\n",
        "\n",
        "    for i in tqdm(range(0, len(paths), batch_size)):\n",
        "        batch_paths = paths[i:i+batch_size]\n",
        "        batch_labels = labels[i:i+batch_size]\n",
        "\n",
        "        batch_imgs = []\n",
        "        batch_extras = []\n",
        "        batch_y = []\n",
        "\n",
        "        for p, lab in zip(batch_paths, batch_labels):\n",
        "            img = read_image(p, IMG_SIZE)\n",
        "            if img is None:\n",
        "                continue\n",
        "            batch_imgs.append(img)\n",
        "            batch_extras.append(simple_extra_features(img))\n",
        "            batch_y.append(lab)\n",
        "\n",
        "        if len(batch_imgs) == 0:\n",
        "            continue\n",
        "\n",
        "        batch_imgs = np.array(batch_imgs, dtype=np.float32)\n",
        "        batch_imgs = preprocess_input(batch_imgs)\n",
        "        emb = base_model.predict(batch_imgs, verbose=0)\n",
        "\n",
        "        X_embed.append(emb)\n",
        "        X_extra.append(np.array(batch_extras))\n",
        "        y_out.extend(batch_y)\n",
        "\n",
        "    understanding = (len(y_out), \"samples processed\")\n",
        "    print(\"Embeddings:\", understanding)\n",
        "\n",
        "    X_embed = np.vstack(X_embed) if len(X_embed) else np.empty((0, 1280))\n",
        "    X_extra = np.vstack(X_extra) if len(X_extra) else np.empty((0, 3))\n",
        "    return X_embed, X_extra, y_out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FExFbuTnxe5C"
      },
      "source": [
        "Extract embeddings for train/val/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q7WHM8Axe5C"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "Xtr_emb, Xtr_extra, ytr = extract_embeddings(train_paths, train_labels)\n",
        "Xva_emb, Xva_extra, yva = (np.empty((0,1280)), np.empty((0,3)), [])\n",
        "Xte_emb, Xte_extra, yte = (np.empty((0,1280)), np.empty((0,3)), [])\n",
        "\n",
        "if len(val_paths) > 0:\n",
        "    Xva_emb, Xva_extra, yva = extract_embeddings(val_paths, val_labels)\n",
        "\n",
        "if len(test_paths) > 0:\n",
        "    Xte_emb, Xte_extra, yte = extract_embeddings(test_paths, test_labels)\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"Train:\", Xtr_emb.shape, Xtr_extra.shape)\n",
        "print(\"Val  :\", Xva_emb.shape, Xva_extra.shape)\n",
        "print(\"Test :\", Xte_emb.shape, Xte_extra.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na4YMgsjxe5C"
      },
      "source": [
        "Combine CNN embeddings + engineered features, encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeCY4qTOxe5C"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "Xtr = np.hstack([Xtr_emb, Xtr_extra])\n",
        "Xva = np.hstack([Xva_emb, Xva_extra]) if len(yva) > 0 else None\n",
        "Xte = np.hstack([Xte_emb, Xte_extra]) if len(yte) > 0 else None\n",
        "\n",
        "le = LabelEncoder()\n",
        "ytr_enc = le.fit_transform(ytr)\n",
        "yva_enc = le.transform(yva) if len(yva) > 0 else None\n",
        "yte_enc = le.transform(yte) if len(yte) > 0 else None\n",
        "\n",
        "print(\"Classes:\", list(le.classes_))\n",
        "print(\"Train X/y:\", Xtr.shape, ytr_enc.shape)\n",
        "// comments none existent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqlQ_FaQxe5C"
      },
      "source": [
        "## 7) Train XGBoost model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bJqo1j_xe5C"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "num_classes = len(le.classes_)\n",
        "\n",
        "clf = xgb.XGBClassifier(\n",
        "    n_estimators=600,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective=\"multi:softprob\",\n",
        "    num_class=num_classes,\n",
        "    eval_metric=\"mlogloss\",\n",
        "    tree_method=\"hist\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "if Xva is not None:\n",
        "    clf.fit(Xtr, ytr_enc, eval_set=[(Xva, yva_enc)], verbose=False)\n",
        "else:\n",
        "    clf.fit(Xtr, ytr_enc, verbose=False)\n",
        "\n",
        "print(\"Training done.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9PuSfYExe5D"
      },
      "source": [
        "## 8) Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_xDRkS1xe5D"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def evaluate(X, y_enc, title=\"Evaluation\"):\n",
        "    pred = clf.predict(X)\n",
        "    acc = accuracy_score(y_enc, pred)\n",
        "    print(title, \"Accuracy:\", acc)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_enc, pred, target_names=le.classes_))\n",
        "\n",
        "    cm = confusion_matrix(y_enc, pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
        "    disp.plot(values_format='d')\n",
        "    plt.title(title)\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.show()\n",
        "\n",
        "if Xva is not None and len(yva) > 0:\n",
        "    evaluate(Xva, yva_enc, \"Validation\")\n",
        "\n",
        "if Xte is not None and len(yte) > 0:\n",
        "    evaluate(Xte, yte_enc, \"Test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsK1DDLIxe5D"
      },
      "source": [
        "## 9) Save model + label encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTRXqnKlxe5D"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "MODEL_OUT = \"/content/drive/MyDrive/cctv_xgb_model.pkl\"\n",
        "ENCODER_OUT = \"/content/drive/MyDrive/cctv_label_encoder.pkl\"\n",
        "\n",
        "joblib.dump(clf, MODEL_OUT)\n",
        "joblib.dump(le, ENCODER_OUT)\n",
        "\n",
        "print(\"Saved:\", MODEL_OUT)\n",
        "print(\"Saved:\", ENCODER_OUT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsEHjhjSxe5D"
      },
      "source": [
        "## 10) Basic Program: Predict on a new image (ALERT system)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovi2OTPuxe5D"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "clf = joblib.load(MODEL_OUT)\n",
        "le  = joblib.load(ENCODER_OUT)\n",
        "\n",
        "def predict_image(image_path, alert_threshold=0.65):\n",
        "    img = read_image(image_path, IMG_SIZE)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    x_extra = simple_extra_features(img).reshape(1, -1)\n",
        "\n",
        "    x = preprocess_input(np.array([img], dtype=np.float32))\n",
        "    emb = base_model.predict(x, verbose=0)\n",
        "\n",
        "    feats = np.hstack([emb, x_extra])\n",
        "    probs = clf.predict_proba(feats)[0]\n",
        "\n",
        "    top_idx = int(np.argmax(probs))\n",
        "    top_label = le.inverse_transform([top_idx])[0]\n",
        "    top_conf = float(probs[top_idx])\n",
        "\n",
        "    alert = (top_label != \"normal\") and (top_conf >= alert_threshold)\n",
        "\n",
        "    return {\n",
        "        \"label\": top_label,\n",
        "        \"confidence\": top_conf,\n",
        "        \"alert\": alert,\n",
        "        \"all_probs\": {le.classes_[i]: float(probs[i]) for i in range(len(probs))}\n",
        "    }\n",
        "\n",
        "def pretty_print_result(res):\n",
        "    if res is None:\n",
        "        print(\"Could not read image.\")\n",
        "        return\n",
        "    print(\"Predicted:\", res[\"label\"], f\"({res['confidence']:.2f})\")\n",
        "    if res[\"alert\"]:\n",
        "        print(\"ðŸš¨ ALERT: Potential incident detected! Notify conductor/security.\")\n",
        "    else:\n",
        "        print(\"âœ… No alert triggered.\")\n",
        "    s = pd.Series(res[\"all_probs\"]).sort_values(ascending=False)\n",
        "    display(s)\n",
        "\n",
        "# Example usage (change path):\n",
        "# res = predict_image(\"/content/drive/MyDrive/test.jpg\")\n",
        "# pretty_print_result(res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x80UKfOpxe5D"
      },
      "source": [
        "## 11) Optional: Video inference (sample frames)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskz5PVBxe5D"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def predict_video(video_path, every_n_frames=10, alert_threshold=0.65):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_id = 0\n",
        "    timeline = []\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_id % every_n_frames == 0:\n",
        "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            rgb = cv2.resize(rgb, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "            x_extra = simple_extra_features(rgb).reshape(1, -1)\n",
        "            x = preprocess_input(np.array([rgb], dtype=np.float32))\n",
        "            emb = base_model.predict(x, verbose=0)\n",
        "            feats = np.hstack([emb, x_extra])\n",
        "\n",
        "            probs = clf.predict_proba(feats)[0]\n",
        "            top_idx = int(np.argmax(probs))\n",
        "            label = le.inverse_transform([top_idx])[0]\n",
        "            conf = float(probs[top_idx])\n",
        "            alert = (label != \"normal\") and (conf >= alert_threshold)\n",
        "\n",
        "            timeline.append((frame_id, label, conf, alert))\n",
        "\n",
        "        frame_id += 1\n",
        "\n",
        "    cap.release()\n",
        "    return timeline\n",
        "\n",
        "# Example:\n",
        "# timeline = predict_video(\"/content/drive/MyDrive/bus_incident.mp4\")\n",
        "# timeline[:10]\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}